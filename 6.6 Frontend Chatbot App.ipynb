{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c738671d",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Prelude\n",
    "\n",
    "In the rapidly evolving landscape of technology, the practical application of AI models stands as a cornerstone for innovation and efficiency. This documentation, built upon our experiences while enhancing a stock trading platform, serves as a robust starting point for both newcomers and seasoned professionals in the field of data science and software development.\n",
    "\n",
    "The focal point of this material is not solely the stock trading domain, but the underlying concepts and technologies that drive such advancements. By using a stock trading platform as a real-world example, we demonstrate the implementation of dynamic features such as real-time data retrieval and interactive chatbots, which are universally applicable across various domains.\n",
    "\n",
    "We emphasize the integration of these features in a front-end user interface, fostering a comprehensive understanding of both backend functionalities and their representation in a user-friendly manner. Our goal is to encourage enthusiasts from all backgrounds to leverage this material as a springboard for exploring, learning, and implementing innovative solutions using generative AI and other modern technologies.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8777ba6",
   "metadata": {},
   "source": [
    "# Enhancing the Stock Trading Platform with Real-time Data and Interactive Features\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The following steps outlines the significant updates implemented in our stock trading platform. The improvements include real-time stock price data integration, news article aggregation related to individual stocks, and a chatbot feature which simulates responses from Warren Buffet, utilizing Anthropic's Claude model.\n",
    "\n",
    "## Step 1: Real-time Stock Price Integration\n",
    "\n",
    "### Overview\n",
    "To provide users with the most current stock prices, we implemented a feature that fetches real-time stock data from the `yfinance` library. This data is then displayed on the user interface, enhancing the user experience by offering the most recent stock market information.\n",
    "\n",
    "### Implementation\n",
    "In the Flask backend (`app.py`), we set up an API endpoint to obtain the latest stock prices from the `yfinance` library. Here is a snippet of the Python function that fetches the stock prices:\n",
    "\n",
    "```python\n",
    "def get_intraday_price(symbol, interval='1m'):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    intraday_data = ticker.history(period=\"1d\", interval=interval)\n",
    "    ...\n",
    "```\n",
    "\n",
    "On the frontend (`index.tsx`), a React `useEffect` hook was used to call the Flask API at regular intervals to update the stock prices displayed on the user interface.\n",
    "\n",
    "```javascript\n",
    "useEffect(() => {\n",
    "    const fetchPrices = async () => {\n",
    "        ...\n",
    "        await Promise.all(fetchPricePromises);\n",
    "        setStockPrices(prices);\n",
    "    };\n",
    "    fetchPrices();\n",
    "    ...\n",
    "}, [stocksData]);\n",
    "```\n",
    "\n",
    "## Step 2: News Article Aggregation\n",
    "\n",
    "### Overview\n",
    "To aid users in making informed decisions, we added a feature that aggregates recent news articles pertaining to specific stocks. This feature scrapes news data from Yahoo Finance and stores it locally.\n",
    "\n",
    "### Implementation\n",
    "The aggregation process involves utilizing the `yfinance` library to extract news URLs, followed by using `BeautifulSoup` to scrape the content of these articles. This data is then stored locally in JSON files, which are updated daily. Here is a snippet demonstrating how news articles are aggregated:\n",
    "\n",
    "```python\n",
    "def get_news(stock_list):\n",
    "    ...\n",
    "    for stock in stock_list:\n",
    "        ticker = yf.Ticker(stock)\n",
    "        news_data = ticker.news\n",
    "        ...\n",
    "        response = requests.get(link, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        ...\n",
    "```\n",
    "\n",
    "## Step 3: Storing Articles in JSON and PostgreSQL\n",
    "\n",
    "### Overview\n",
    "After the news articles are aggregated, they are stored in JSON files. These articles are also stored in a PostgreSQL database, allowing for structured storage and efficient retrieval of the news data.\n",
    "\n",
    "### Implementation\n",
    "In the Flask application, a routine is established to read the stored JSON files and populate the PostgreSQL database with the news data. This ensures that the latest news articles are readily available for retrieval. Here is a snippet showcasing the storage and retrieval process:\n",
    "\n",
    "```python\n",
    "def insert_news_to_db():\n",
    "    news_dir = 'news'\n",
    "    for file_name in os.listdir(news_dir):\n",
    "        if file_name.endswith('.json'):\n",
    "            ...\n",
    "            with open(os.path.join(news_dir, file_name)) as f:\n",
    "                news_data = json.load(f)\n",
    "                ...\n",
    "                new_entry = News(ticker=ticker, news=news_text, as_of_date=as_of_date)\n",
    "                db.session.add(new_entry)\n",
    "                db.session.commit()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of the steps so far:\n",
    "\n",
    "Having set up a reliable data pipeline, we are now equipped with a rich reservoir of real-time data. This not only serves as a robust back-end support for our trading platform but also paves the way for sophisticated features, such as the interactive chatbot. The essence of this phase is to harness the potential of real-time data, enhancing the analytical depth and user engagement of the platform. Now, we transition into leveraging this data to fuel an interactive chatbot feature, aiming to simulate insightful responses for user queries.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Implementing the Chatbot Feature\n",
    "\n",
    "### Overview\n",
    "To escalate user engagement and provide insightful interactions, we introduced a chatbot feature that simulates responses from Warren Buffet, facilitated by Anthropic's Claude model. This section also illustrates how a similar goal can be achieved using OpenAI's GPT-4, emphasizing the flexible approach to integrating AI models for interactive features.\n",
    "\n",
    "### Implementation\n",
    "The Flask backend, upon receiving the user's question, identifies the stock ticker mentioned in the query and aggregates the recent news about the stock. This aggregated data, combined with the user's question, forms a comprehensive prompt for the Claude model, which then generates a thoughtful response. Below is a snippet illustrating the Flask endpoint and the method of invoking the Anthropic API:\n",
    "\n",
    "```python\n",
    "@app.route('/ask_warren', methods=['POST'])\n",
    "def ask_warren():\n",
    "    user_question = request.json.get('userQuestion')\n",
    "    ...\n",
    "    response = client.messages.create(\n",
    "        model=\"YOUR_MODEL_NAME\",\n",
    "        messages=[{\"role\": \"user\", \"content\": base_prompt}, {\"role\": \"assistant\", \"content\": \"\"}],\n",
    "        ...\n",
    "    )\n",
    "    return jsonify({\"response\": response_content})\n",
    "```\n",
    "\n",
    "Furthermore, a similar approach can be applied with OpenAI's GPT-4. For instance, you can construct a prompt with metadata and user questions to generate responses:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "openai.api_key = 'your-openai-api-key-here'\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-4\",\n",
    "  prompt=f\"Stock Ticker: {ticker}\\nRecent News: {ticker_news}\\nUser Question: {user_question}\\n\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=150\n",
    ")\n",
    "```\n",
    "\n",
    "On the frontend, we established a chat interface that promotes a fluid interaction with the chatbot, rendering the conversation in a user-friendly format. The interaction with the Flask backend is facilitated through HTTP requests, as demonstrated below:\n",
    "\n",
    "```javascript\n",
    "const handleQuestionSubmit = async () => {\n",
    "    const response = await fetch(\"http://localhost:5002/ask_warren\", {\n",
    "        ...\n",
    "    });\n",
    "    const data = await response.json();\n",
    "    setChatHistory([...chatHistory, { role: \"user\", content: userQuestion }, { role: \"warren\", content: data.response }]);\n",
    "    setUserQuestion(\"\");\n",
    "};\n",
    "```\n",
    "\n",
    "By adopting these strategies, the stock trading platform is now fortified with features that not only offer users real-time stock data and the latest news articles on particular stocks but also facilitate interactive dialogues with a chatbot, enhancing the overall user experience and equipping users with valuable insights for making informed trading decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d2b40",
   "metadata": {},
   "source": [
    "# Prompt Engineering in AI Models\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the field of AI, particularly in Natural Language Processing (NLP), prompt engineering plays a vital role. It refers to the process of crafting prompts that guide the AI model to generate desired responses. The effectiveness of an AI model in delivering accurate and insightful responses can often be significantly improved through careful and intelligent prompt engineering.\n",
    "\n",
    "## Importance of Prompt Engineering\n",
    "\n",
    "Prompt engineering is crucial for several reasons:\n",
    "1. **Accuracy**: Well-engineered prompts can help in getting more accurate responses from the model.\n",
    "2. **Specificity**: Helps in narrowing down the response to suit the specific needs or contexts of the query.\n",
    "3. **Efficiency**: Reduces the chances of receiving irrelevant or verbose answers, thereby saving time and computational resources.\n",
    "\n",
    "By understanding and leveraging the nuances of prompt engineering, it is possible to extract more valuable insights from AI models, making them more potent tools in various applications, including data analysis, content creation, and many others.\n",
    "\n",
    "## Comparing Original and Revised Prompts\n",
    "\n",
    "### Original Prompt\n",
    "\n",
    "The original prompt had a structured approach, guiding the AI to analyze the ticker and corresponding news to answer the user's question. However, the scope was somewhat limited, and the AI would often respond with a generic message if the news data didn't contain sufficient information to answer the question. Here is the format of the original prompt:\n",
    "\n",
    "```xml\n",
    "<prompt>\n",
    "  <role>\n",
    "    As an investment portfolio assistant, I am designed to answer any and all investment-related queries to the best of my ability. My purpose is to provide helpful insights and guidance based on the information provided to me.\n",
    "  </role>\n",
    "\n",
    "  <task>\n",
    "    Analyze the given {ticker} and its corresponding {ticker_news}, and provide a concise answer to the {user_question}. The response should be based solely on the information present in the {ticker_news} and should not exceed 100 words. If the necessary information to answer the question is not found in the {ticker_news}, simply respond with \"Sorry, as an AI assistant, I'm not able to answer based on the information provided.\"\n",
    "  </task>\n",
    "\n",
    "  <analysis>\n",
    "    1. Extract relevant information from the {ticker_news} that pertains to the {user_question}.\n",
    "    2. Correlate the extracted information to formulate a concise and accurate answer.\n",
    "    3. If the {ticker_news} does not contain sufficient information to answer the {user_question}, do not attempt to fill in the gaps or make assumptions.\n",
    "  </analysis>\n",
    "\n",
    "  <response>\n",
    "    If information is available:\n",
    "      Provide a clear, concise answer to the {user_question} based on the correlated information from the {ticker_news}. Limit the response to 100 words.\n",
    "\n",
    "    If information is not available:\n",
    "      \"Sorry, as an AI assistant, I'm not able to answer based on the information provided.\"\n",
    "  </response>\n",
    "</prompt>\n",
    "```\n",
    "\n",
    "### Revised Prompt\n",
    "\n",
    "The revised prompt, on the other hand, introduces a more comprehensive approach by incorporating additional data (`{ticker_info}`) and expanding the task's scope to include investment advice and price predictions. This results in more thoughtful and meaningful responses from the AI. Here is the format of the revised prompt:\n",
    "\n",
    "```xml\n",
    "<prompt>\n",
    "  <role>\n",
    "    As an investment portfolio assistant, I am designed to provide financial investment advice and insights based on the available information. My purpose is to offer helpful guidance and predictions to support investment decisions.\n",
    "  </role>\n",
    "\n",
    "  <task>\n",
    "    Analyze the given {ticker} using the corresponding {ticker_news} and {ticker_info}. Provide a thoughtful answer to the {user_question}, offering investment advice and price movement predictions when requested. The response should be based on the information present in the {ticker_news} and {ticker_info}, and should not exceed 150 words. If the necessary information to answer the question is not found in either source, respond with \"Sorry, as an AI assistant, I don't have enough information to provide a complete answer.\"\n",
    "  </task>\n",
    "\n",
    "  <analysis>\n",
    "    1. Extract relevant information from the {ticker_news} and {ticker_info} that pertains to the {user_question}.\n",
    "    2. Correlate the extracted information to formulate a comprehensive and insightful answer.\n",
    "    3. If the {user_question} involves price movement predictions, utilize the available price data and other relevant information from {ticker_info} to make an informed forecast.\n",
    "    4. If the {ticker_news} and {ticker_info} do not contain sufficient information to fully address the {user_question}, provide a partial answer based on the available data and acknowledge the limitations.\n",
    "  </analysis>\n",
    "\n",
    "  <response>\n",
    "    If sufficient information is available:\n",
    "      Provide a clear, thoughtful answer to the {user_question}, offering investment advice and price movement predictions as requested. Cite relevant information from the {ticker_news} and {ticker_info} to support your response. Limit the answer to 150 words.\n",
    "\n",
    "    If partial information is available:\n",
    "      Provide an answer to the {user_question} based on the available information from the {ticker_news} and {ticker_info}. Acknowledge that the response may be limited due to incomplete data. Limit the answer to 150 words.\n",
    "\n",
    "    If no relevant information is available:\n",
    "      \"Sorry, as an AI assistant, I don't have enough information to provide a complete answer.\"\n",
    "  </response>\n",
    "</prompt>\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">In the revised prompt we are additionally, providing the dump of `ticker.info` to allow the model to correlare the daily news with its fundamentals and price to draw meaningful analysis.</div>\n",
    "\n",
    "Through the revision, we expect to receive more meaningful responses, with the AI leveraging a richer set of data to provide insightful answers, potentially offering a more rewarding user experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de3304",
   "metadata": {},
   "source": [
    "# Implementing Guardrails in AI Systems\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the context of AI systems, guardrails are mechanisms put in place to ensure that the AI operates within defined boundaries, ensuring safety, reliability, and adherence to intended goals. Implementing guardrails is an essential step in deploying AI models, particularly when the AI is interacting with users in real-time, offering responses or suggestions based on user inputs.\n",
    "\n",
    "## Importance of Guardrails\n",
    "\n",
    "Guardrails in AI systems serve several crucial functions:\n",
    "\n",
    "1. **Safety**: They prevent the AI from generating harmful, inappropriate, or misleading responses.\n",
    "2. **Reliability**: By constraining the AI's operation within known boundaries, guardrails ensure that the AI performs reliably, providing expected results across different scenarios.\n",
    "3. **Legal and Ethical Compliance**: Guardrails help in ensuring that the AI operates within the legal and ethical boundaries defined by society, thus protecting the users and the developers from legal repercussions.\n",
    "4. **User Experience**: They help in shaping the user experience, preventing the AI from going off on tangents and keeping the interactions focused and meaningful.\n",
    "\n",
    "## Implementation in Our Project\n",
    "\n",
    "In our project, we implemented guardrails through several mechanisms:\n",
    "\n",
    "1. **Prompt Engineering**: By designing prompts carefully, we guided the AI to respond within the desired frameworks, avoiding irrelevant or inappropriate content generation. As showcased in the earlier section, our revised prompt structure is an example of a guardrail, guiding the AI's responses to be more meaningful and aligned with the project's goals.\n",
    "   \n",
    "2. **Response Filtering**: We implemented filters on the AI's responses, preventing the display of content that violates predefined rules or criteria, such as inappropriate content or information that could potentially be misleading.\n",
    "\n",
    "3. **Feedback Loops**: Our system includes feedback mechanisms, allowing users to report unsatisfactory AI responses. This feedback is used to further train the AI, improving its performance and adherence to the guardrails over time.\n",
    "\n",
    "## Hypothetical Implementation of Response Filtering\n",
    "\n",
    "To better illustrate how response filtering can be implemented as a guardrail, let's consider a hypothetical function `is_response_appropriate` that we could add to our Python Flask application. This function would analyze the AI's generated response and determine if it meets the criteria for an appropriate and meaningful answer.\n",
    "\n",
    "Here's a simplified version of how this function might look and how it could be integrated into the response generation process:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "# List of inappropriate words or phrases that we want to filter out\n",
    "INAPPROPRIATE_CONTENT = [\"inappropriate_word1\", \"inappropriate_phrase1\", \"inappropriate_word2\"]\n",
    "\n",
    "def is_response_appropriate(response):\n",
    "    \"\"\"\n",
    "    This function checks the AI's response for any inappropriate content or \n",
    "    phrases that are not allowed as per our guardrails.\n",
    "    \"\"\"\n",
    "    for content in INAPPROPRIATE_CONTENT:\n",
    "        if re.search(content, response, re.IGNORECASE):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def generate_response(prompt):\n",
    "    # ... (code to generate response based on the prompt)\n",
    "    response = ai.generate_response(prompt)\n",
    "\n",
    "    # Applying guardrails\n",
    "    if not is_response_appropriate(response):\n",
    "        response = \"I'm sorry, I cannot provide a response to that input.\"\n",
    "\n",
    "    return response\n",
    "```\n",
    "\n",
    "In this example, the `is_response_appropriate` function scans the AI-generated response for any inappropriate content listed in the `INAPPROPRIATE_CONTENT` list. If any inappropriate content is found, it returns `False`, causing the `generate_response` function to replace the AI's response with a default apology message.\n",
    "\n",
    "This is a simple demonstration and in a real-world application, the function could be expanded to include more complex analysis and filtering mechanisms to ensure the AI's responses adhere to the defined guardrails.\n",
    "\n",
    "\n",
    "By implementing these guardrails, we ensured that our AI system operates safely and reliably, offering a positive and meaningful user experience while adhering to legal and ethical standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2d1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
