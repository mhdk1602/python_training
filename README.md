# Data Engineering with Python Training

This training repository provides an introduction to data engineering in `python`, covering topics such as data modeling, schema design, storage and retrieval, data processing and transformation, and data pipelines and ETL processes. Participants will also learn how to use Python to interact with cloud-based data engineering services, such as AWS Glue, Google Cloud Dataflow, or Azure Data Factory.

Upon covering basic data modeling and engineering concepts, we also explore standing up real-time front end applications with backend db setup, exploring Generative AI, and its applications.

The repository includes hands-on exercises and examples, as well as resources for further learning and exploration.

## Proposed Syllabus

0. Fundamentals
    * [Introduction to Github]
    * [Getting Started with Python]
        * [Functions]
        * [Looping]
        * [Reading Data]
    * [Getting Started with Jupyter Notebooks]

1. Introduction to Data Engineering

    * [Overview of data engineering and its role in the data pipeline]
    * [Key concepts and terminology in data engineering]
    * [Common data formats and structures]

2. Data Modeling and Schema Design

    * [Introduction]
    * [NoSQL databases and data modeling]
    * [Schema Modeling]
    * [Data Modeling Exercise]

3. [Data Storage and Retrieval]

    * Overview of different types of data storage systems (e.g. file systems, databases, data lakes)
    * Reading and writing data from various storage systems in Python (e.g. CSV, JSON, Parquet)
    * Best practices for managing data storage and retrieval

4. [Data Processing and Transformation]

    * Introduction to Data Processing and Transformation

        * Definition
        * Importance in Data Engineering

    * Data Cleaning

        * Handling Missing Values
        * Removing Duplicates
        * Code examples

    * Data Filtering

        * Definition and Importance
        * Techniques for Data Filtering
        * Code examples: Basic and Advanced

    * Data Aggregation

        * Definition and Importance
        * Techniques for Data Aggregation
        * Code examples

    * Tools and Libraries

        * Pandas: Overview and Code examples
        * NumPy: Overview and Code examples
        * Dask: Overview and Code examples

    * Optimizing Data Processing and Transformation Pipelines

        * Best Practices
        * Code examples

5. [Data Streaming and Real-time Processing]

    * Introduction to data streaming and real-time processing
    * Tools and libraries for real-time data processing in Python (e.g., Apache Kafka, Apache Flink, Faust)
    * Best practices for implementing real-time data processing pipelines

6. Data Integration and APIs

    * [Introduction to data integration and APIs in data engineering]
    * [Working with APIs in Python (e.g., REST, GraphQL)]
    * [Introduction to GraphQL]
    * [Postgres/Postgraphile Setup]
    * [NextJS front-end application for GraphQL]
    * [Migration to Hasura]
    * [Implementing a chatbot on our Stock Trading Platform Application]
        * Recommended after Chapter 7

7. Text Comparison

    * [Fuzzy Matching, Levenshtein Distance, & Other text comparison algorithms]
    * [Text Embeddings]
    * [Embeddings in Data Engineering]

8. Data Quality and Validation

    * Importance of data quality and validation in data engineering
    * Techniques for validating and ensuring data quality in Python (e.g., data profiling, data validation frameworks)
    * Best practices for incorporating data quality checks in data pipelines

9. Data Pipelines and ETL

    * Overview of data pipelines and ETL (Extract, Transform, Load) processes
    * Building data pipelines in Python using tools such as Apache Airflow, Luigi, or Prefect
    * Best practices for designing and managing data pipelines

10. Data Engineering in the Cloud

    * Overview of cloud computing and its benefits for data engineering
    * Common cloud-based data engineering services (e.g. AWS Glue, Google Cloud Dataflow, Azure Data Factory)
    * Using Python to interact with cloud-based data engineering services
    * Best practices for designing and managing cloud-based data engineering pipelines

11. Conclusion and Next Steps

    * Recap of key concepts and tools covered in the training
    * Discussion of potential next steps for participants (e.g. advanced topics, hands-on projects)
    * Additional resources for learning more about data engineering in Python and the cloud
