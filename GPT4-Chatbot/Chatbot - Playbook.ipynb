{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e827616",
   "metadata": {},
   "source": [
    "௳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c207e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Prevent truncation of column width\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9576addc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting annoy\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for annoy: filename=annoy-1.17.3-cp39-cp39-macosx_14_0_arm64.whl size=61775 sha256=c69bd34c73ceb2e8831134e91697d9d7d212945fa36592b5d775438760809672\n",
      "  Stored in directory: /Users/malempatiharidines/Library/Caches/pip/wheels/09/a9/54/37478e65995fe712f7da465749da9ddb21db6b1a599d591ac7\n",
      "Successfully built annoy\n",
      "Installing collected packages: annoy\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed annoy-1.17.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install annoy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c296f3",
   "metadata": {},
   "source": [
    "# Building a Knowledge-Based Chatbot with Anthropic and Vector Similarity Search\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will demonstrate how to develop a knowledge-based chatbot that leverages Anthropic's state-of-the-art language models to analyze and answer questions based on the content of a PDF document. The process encompasses several phases including extracting and analyzing text data from a PDF, creating contextual embeddings, and setting up a chatbot with the ability to search through embeddings to generate responses.\n",
    "\n",
    "## Step 1: PDF File Processing and Analysis\n",
    "\n",
    "### 1. PDF File Parsing\n",
    "- **File Reading**: Load the 'Tom-Sawyer.pdf' file.\n",
    "- **Content Extraction**: Extract text from the PDF and divide it into smaller, manageable chunks.\n",
    "\n",
    "### 2. Content Analysis using Anthropic\n",
    "- **Text Analysis with Anthropic**: Utilize Anthropic's language model to analyze the text chunks, extracting concise summaries and key insights.\n",
    "- **Saving Analysis Results**: Store the analysis results into JSON files for later use.\n",
    "\n",
    "### 3. Creating Contextual Embeddings\n",
    "- **Contextual Embedding**: Generate contextual embeddings of the analyzed text using a Sentence Transformer model.\n",
    "- **Embedding Verification**: Verify the number of embeddings created and ensure their correctness.\n",
    "\n",
    "## Step 2: Setting Up a Vector Similarity Search Index\n",
    "\n",
    "### 1. Vector Indexing\n",
    "- **Index Initialization**: Create an index using a similarity search library (like Annoy) to store the contextual embeddings.\n",
    "- **Embedding Indexing**: Add the contextual embeddings to the index, enabling efficient similarity search.\n",
    "\n",
    "### 2. Chatbot Setup and Query Handling\n",
    "- **Chatbot Model Setup**: Initialize a new instance of the Anthropic language model to act as the chatbot.\n",
    "- **User Interaction**: Set up an interaction loop where the user can ask questions.\n",
    "- **Utilizing RAG for Response Generation**: Develop a function to generate responses using a Retrieve-and-Generate (RAG) setup, which involves querying the index for similar embeddings and using them to generate responses with the Anthropic model.\n",
    "\n",
    "### 3. Response Generation and Interaction\n",
    "- **Response Generation**: Generate responses to user questions based on the most similar text segments retrieved from the index.\n",
    "- **User Interaction**: Allow users to interact with the chatbot and ask questions to receive responses generated based on the knowledge extracted from the PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6988444",
   "metadata": {},
   "source": [
    "### Step 1.1: Setting Up the Environment\n",
    "\n",
    "In this step, we will prepare our environment for the development of the chatbot and the analysis of the PDF document. It involves installing necessary libraries and importing the required modules. Setting up a well-prepared environment is crucial for the smooth progression of our project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316480d7",
   "metadata": {},
   "source": [
    "## Step 1: Process and Analyze the \"Tom-Sawyer.pdf\" File\n",
    "\n",
    "In this step, we will concentrate on processing the 'Tom-Sawyer.pdf' file located in the 'gitignore-files' directory. The process will involve parsing the content of the PDF and then using Anthropic models for analysis. We aim to achieve a fully analyzed and condensed output by the end of this step. Here's a step-by-step breakdown:\n",
    "\n",
    "### 1.a Full Setup to Parse and Analyze the PDF using Anthropic\n",
    "\n",
    "#### i. Chunking\n",
    "- Read the PDF file and extract its content.\n",
    "- Implement chunking to divide the text into manageable sections, ensuring the context is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e10a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757fbfc72265451c93abfee60a36487e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting pages:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE ADVENTURES OF TOM SAWYER  \n",
      " \n",
      "BY MARK TWAIN \n",
      "(Samuel Langhorne Clemens) \n",
      " \n",
      "Complete \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Ebd \n",
      "E-BooksDirectory.com \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "PREFACE \n",
      " \n",
      "Most of the adventures recorded in this book really occurred; one or two were \n",
      "experiences of my own, the rest those of boys who were schoolmates of mine. \n",
      "Huck Finn is drawn from life; Tom Sawyer also, but not from an individual—he is \n",
      "a combination of the characteristics of three boys whom I knew, and therefore \n",
      "belongs to the composite order of architecture. \n",
      "The odd superstitions touched upon were all prevalent among children and \n",
      "slaves in the West at the period of this story—that is to say, thirty or forty years \n",
      "ago. \n",
      "Although my book is intended mainly for the entertainment of boys and girls, I \n",
      "hope it will not be shunned by men and women on that account, for part of my \n",
      "plan has been to try to pleasantly remind adults of what they once were \n",
      "themselves, and of how they felt and thought and talked, and what queer \n",
      "enterprises they sometimes engaged in. \n",
      "THE AUTHOR. \n",
      "HARTFORD, 1876. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE ADVENTURES OF TOM SAWYER  \n",
      " \n",
      "BY MARK TWAIN \n",
      "(Samuel Langhorne Clemens) \n",
      " \n",
      "Part 1. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Ebd \n",
      "E-BooksDirectory.com \n",
      " \n",
      " \n",
      "CHAPTER I \n",
      "\"TOM!\" \n",
      "No answer. \n",
      "\"TOM!\" \n",
      "No answer. \n",
      "\"What's gone with that boy,  I wonder? You TOM!\" \n",
      "No answer. \n",
      "The old lady pulled her spectacles down and looked over them about the room; \n",
      "then she put them up and looked out under them. She seldom or never looked \n",
      "THROUGH them for so small a thing as a boy; they were her state pair, the pride \n",
      "of her heart, and were built for \"style,\" not service—she could have seen through a \n",
      "pair of stove-lids just as well. She looked perplexed for a moment, and then said, \n",
      "not fiercely, but still loud enough for the furniture to hear: \n",
      "\"Well, I lay if I get hold of you I'll—\" \n",
      "She did not finish, for by this time she was bending down and punching under \n",
      "the bed with the broom, and so she needed breath to punctuate the punches with. \n",
      "She resurrected nothing but the cat. \n",
      "\"I never did see the beat of that boy!\" \n",
      "She went to the open door and stood in it and looked out among th\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf_with_progress(pdf_path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Initialize an empty string for the text\n",
    "    text = ''\n",
    "    \n",
    "    # Iterate through each page in the PDF\n",
    "    for page in tqdm(doc, desc=\"Extracting pages\"):\n",
    "        # Extract text from the current page and append it to the text string\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Close the PDF after extraction\n",
    "    doc.close()\n",
    "    \n",
    "    # Return the extracted text\n",
    "    return text\n",
    "\n",
    "# Use the function to extract text and include a progress bar\n",
    "pdf_text = extract_text_from_pdf_with_progress('../gitignore-files/Tom-Sawyer.pdf')\n",
    "print(pdf_text[:2155])  # Print the first 2155 characters or adjust as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a8b1b",
   "metadata": {},
   "source": [
    "### Text Chunking for Efficient Analysis\n",
    "\n",
    "In this section of our notebook, we employ a method to divide the extracted text from the PDF file into smaller, manageable pieces, commonly known as \"chunks\". This process is a crucial step to facilitate the efficient analysis of large texts by breaking them down into more digestible parts, which can be processed individually. Here's a breakdown of the code and the rationale behind selecting a chunk size of 5000 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de9f8e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22952d9d251c4a58be05ae5b1436d9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking text:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ADVENTURES OF TOM SAWYER BY MARK TWAIN (Samuel Langhorne Clemens) Complete Ebd E-BooksDirectory.com PREFACE Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. Huck Finn is drawn from life; Tom Sawyer also, but not from an individual—he is a combination of the characteristics of three boys whom I knew, and therefore belongs to the composite order of architecture. The odd superstitions touche\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def chunk_text(text, chunk_size=5000):\n",
    "    \"\"\"\n",
    "    Function to chunk the text into smaller pieces with a specified chunk size.\n",
    "    The chunk size determines the number of words in each chunk.\n",
    "    \"\"\"\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Initialize an empty list to store the chunks\n",
    "    chunks = []\n",
    "    \n",
    "    # Iterate through the words and create chunks of the specified size\n",
    "    for i in tqdm(range(0, len(words), chunk_size), desc=\"Chunking text\"):\n",
    "        chunk = ' '.join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Chunk the extracted text into sections of 5000 words each (or adjust as needed)\n",
    "pdf_text_chunks = chunk_text(pdf_text, chunk_size=5000)\n",
    "\n",
    "# Print the first chunk as a verification\n",
    "print(pdf_text_chunks[0][:500])  # Print the first 500 characters of the first chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6815e",
   "metadata": {},
   "source": [
    "##### Rationale for 5000 Words Chunk Size\n",
    "\n",
    "We have chosen a chunk size of `5000` words based on the context window limitation of the Anthropic language models. A context window refers to the number of words or tokens that the model can effectively process and analyze in a single instance. Keeping the chunk size at 5000 words allows us to extract meaningful insights from each section without exceeding the model's capacity, ensuring that the analysis is both effective and contextually rich.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d30cbb",
   "metadata": {},
   "source": [
    "### Leveraging Anthropic's Sonnet Model for Large Text Analysis\n",
    "\n",
    "In this segment of the notebook, we have structured a Python script that integrates the Anthropic platform to analyze sizable text chunks. Through this script, we aim to glean concise summaries that highlight key points and insights without sacrificing the context of the content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd4855a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d224e61c084ff983aba97b420993ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing with Anthropic:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b255eb855e854227ace342ad78813431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af55cfe8999746429096ba2bc1629290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8e9ceb02604c76b8f898ad51a05305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034ee9c6a58b40f4b3553200aa18979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f04ee4860ac437fabc3973aa15629c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feebaca0cd5b4403ba431d29cf618d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e874a6f091034253909f49b0618dc14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a40805c5215444ebad981fb01174b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d2a743c5c7486483f2f5c0b3b29b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf7d9ddffba4e2d9adb30cbeb4aea6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eb30d1a4bc49c08fbc4a4896263634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67791448238140e88e22a923eb6cd5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdbac7668b24b509827b2a0965e66bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ffcf817f8c419c9496b5125b10aaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb337e665d6463a87afc2d7db58c24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise summary of the key points and insights from the given text segment:\n",
      "\n",
      "This is the opening of Mark Twain's classic novel The Adventures of Tom Sawyer. The author explains that most of the adventures depicted are based on real events from his own childhood and those of his schoolmates. \n",
      "\n",
      "The story begins by introducing the mischievous protagonist Tom Sawyer, who is scolded by his Aunt Polly for his unkempt appearance after being out playing instead of doing his assigned chore of w\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "client = Anthropic(\n",
    "    api_key=os.getenv(\"CLAUDE_API_KEY\")\n",
    ")\n",
    "\n",
    "#Set model\n",
    "MODEL_NAME = \"claude-3-sonnet-20240229\"\n",
    "\n",
    "def analyze_with_anthropic(text_chunks):\n",
    "    analysis_results = []\n",
    "    prompt = \"<instruction>Analyze the following text segment and provide a concise summary highlighting the key points and insights without losing context of the content.</instruction>\"\n",
    "\n",
    "    system_message = \"<system>You are a helpful AI assistant aiding in condensing text without losing content context.</system>\"\n",
    "\n",
    "    for chunk in tqdm(text_chunks, desc=\"Analyzing with Anthropic\"):\n",
    "        if len(chunk.split()) <= 100000:  # Ensuring we don't exceed the 100K token limit\n",
    "            message_content = prompt + \"\\n\\n<text_segment>\" + chunk + \"</text_segment>\"\n",
    "            message = [\n",
    "                {\"role\": \"user\", \"content\": message_content}, \n",
    "                {\"role\": \"assistant\", \"content\": \"\"}\n",
    "            ]\n",
    "            \n",
    "            with tqdm(total=1, desc=\"Analyzing a chunk\") as pbar:\n",
    "                response = client.messages.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    max_tokens=4000,\n",
    "                    messages=message,\n",
    "                    temperature=0.7,\n",
    "                    system=system_message\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            analysis_results.append(response.content[0].text)\n",
    "        else:\n",
    "            print(f\"Skipping a chunk as it exceeds the 100K token limit.\")\n",
    "    return analysis_results\n",
    "\n",
    "# Analyze the text chunks with the Anthropic model\n",
    "anthropic_analysis_results = analyze_with_anthropic(pdf_text_chunks)\n",
    "\n",
    "# Print the first analysis result as a verification\n",
    "print(anthropic_analysis_results[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd300bc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For this specific analysis, we have chosen the Anthropic's `Sonnet` model, denoted as \"claude-3-sonnet-20240229\". The selection of this model is primarily due to its cost-effectiveness when analyzing large volumes of text. The Sonnet model provides a balance between computational resource utilization and the depth of analysis, making it a more economical choice for tasks involving the scrutiny of extensive text data without compromising the quality of the insights garnered.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0786c7",
   "metadata": {},
   "source": [
    "### Storing Analysis Results as JSON Files\n",
    "\n",
    "In this portion of the notebook, we focus on preserving the analysis results obtained from the Anthropic analysis into individual JSON files. By doing this, we facilitate easier data management and retrieval for future reference or further analysis. \n",
    "\n",
    "The process is fairly straightforward - we create a directory titled \"summary-results\" to store the output files. Within a function named `save_output_to_files`, we iterate over each analysis result and construct a JSON object comprising two attributes: the chunk number and the respective analysis result. Each of these JSON objects is then saved as a separate file in the designated output directory. This method not only ensures the organized storage of data but also streamlines the process of accessing specific chunks of analysis results when needed. The use of JSON format further adds to the convenience by allowing structured storage of data which can be easily parsed and utilized in subsequent steps of the data pipeline.\n",
    "\n",
    "This step is crucial in building a structured dataset from the analyzed results, paving the way for more advanced data operations, such as vectorization and integration into the chatbot system, which are covered in the succeeding steps of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "875e2897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb386a190774768879467bcc61eb987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving Results to Files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Directory to save the output files\n",
    "output_dir = \"summary-results\"\n",
    "\n",
    "def save_output_to_files(analysis_results, output_dir):\n",
    "    for i, result in enumerate(tqdm(analysis_results, desc=\"Saving Results to Files\")):\n",
    "        # Create a JSON object for each result\n",
    "        result_json = {\n",
    "            \"chunk_number\": i,\n",
    "            \"analysis_result\": result\n",
    "        }\n",
    "        \n",
    "        # Create a file for each result\n",
    "        with open(f\"{output_dir}/result_{i}.json\", \"w\") as f:\n",
    "            json.dump(result_json, f, indent=4)\n",
    "\n",
    "# Save the analysis results to files\n",
    "save_output_to_files(anthropic_analysis_results, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5175e4",
   "metadata": {},
   "source": [
    "### Generating Contextual Embeddings using Sentence Transformers\n",
    "\n",
    "In this segment, we undertake the task of creating contextual embeddings for the analyzed text segments. This is a pivotal step in our process as it prepares the data for integration into a vector search index, which would be later used in the chatbot system to fetch relevant responses.\n",
    "\n",
    "We utilize the Sentence Transformers library, a tool that facilitates the generation of dense vector representations of sentences, to accomplish this. Specifically, we opt for the `paraphrase-mpnet-base-v2` model, a paraphrase identification model fine-tuned to identify semantically equivalent sentences. This choice is motivated by the model's ability to generate highly contextual embeddings, which are crucial in retrieving meaningful and precise responses in a chatbot system.\n",
    "\n",
    "Within a function named `create_contextual_embeddings`, we read the JSON files stored in the previous step, one by one, extracting the analyzed text content. For each of these text segments, we use the selected Sentence Transformer model to create embeddings, thereby converting the text data into a format that can be utilized in similarity computations. These embeddings are accumulated in a list which is returned at the end, representing a collection of vectorized representations of the analyzed text segments.\n",
    "\n",
    "By printing the number of embeddings created, we add a verification step to ensure the correct and successful execution of the embedding process, setting the stage for the subsequent steps where these embeddings will be upserted into a vector search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ed9df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42754fc16f684565851daef291769154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa038a8f0ea4152a3625c10f422b9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8eccb00cfa49c1be1dbe2f680f55c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa62fa0def48698e7052ab976de601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ac0318c3bd4e62b9c1f769d5448d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02af6613c4ea47879bfc7b43aaa27a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74179ba060d480aae3b163550fbe29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8262b1c9759a41839b3a5df0d57aa827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2314fd8321b043a88edfb4d4a778d300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f5128c97804b829e0cc7cf10696641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bb2ff6471d4bccbdff57b081fca522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51adf1c2e37742f4ab022aa595f51855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings created: 15\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Load the BERT-based model\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "\n",
    "def create_contextual_embeddings(output_dir):\n",
    "    embeddings = []\n",
    "    file_paths = glob.glob(f\"{output_dir}/*.json\")\n",
    "\n",
    "    for file_path in tqdm(file_paths, desc=\"Creating Embeddings\"):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            text = data['analysis_result']\n",
    "            embedding = model.encode(text, convert_to_tensor=True)\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Directory where the analyzed text files are saved\n",
    "output_dir = \"summary-results\"\n",
    "\n",
    "# Create contextual embeddings for the analyzed text\n",
    "contextual_embeddings = create_contextual_embeddings(output_dir)\n",
    "\n",
    "# (Optional) Print the number of embeddings created as a verification\n",
    "print(f\"Number of embeddings created: {len(contextual_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d9c74",
   "metadata": {},
   "source": [
    "### Contecual vs Non-contextual embeddings\n",
    "\n",
    "| Aspect                      | Contextual Embeddings                                                                                       | Non-Contextual (Traditional) Embeddings                 |\n",
    "|-----------------------------|------------------------------------------------------------------------------------------------------------|---------------------------------------------------------|\n",
    "| **Definition**              | Embeddings that consider the context in which a word appears to generate its representation.               | Embeddings that represent words based on fixed vectors, regardless of the context in which they appear.       |\n",
    "| **Representation**          | Variable; the representation of a word can change depending on its context within a sentence or document. | Fixed; the representation of a word remains constant, irrespective of its usage context.                      |\n",
    "| **Complexity**              | Generally more complex, involving deep learning models to understand context.                               | Simpler models where words are represented as vectors in a pre-defined vector space.                          |\n",
    "| **Computational Resources** | Typically require more computational resources and time due to the complexity of models.                    | Require less computational resources and time as compared to contextual embeddings.                          |\n",
    "| **Use Cases**               | Highly beneficial in tasks that require understanding of semantic nuances, like sentiment analysis, Q&A systems, summarization, etc. | Suitable for simpler tasks where the focus is on the presence of specific words or terms, like text classification, information retrieval, etc. |\n",
    "| **Examples**                | BERT, GPT-3, RoBERTa, ELMo                                                                                   | Word2Vec, GloVe, FastText, TF-IDF                                          |\n",
    "| **When to Use**             | When high levels of semantic understanding and differentiation are required.                                  | When the task is more about understanding the document as a collection of individual words or when computational resources are limited. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbee23b",
   "metadata": {},
   "source": [
    "## Annoy Index Setup\n",
    "\n",
    "In this section of the script, we are implementing the necessary procedures to establish an Annoy index, which will be responsible for managing and storing the vector embeddings derived from the text analysis. The process is delineated in the following steps:\n",
    "\n",
    "### **Step 1: Initializing the Annoy Index**\n",
    "- Import the `AnnoyIndex` class from the Annoy package.\n",
    "- Initialize the Annoy index with the appropriate number of dimensions, which corresponds to the length of the contextual embeddings.\n",
    "\n",
    "### **Step 2: Adding Embeddings to the Index**\n",
    "- Iterate over the contextual embeddings, and for each embedding, it is added to the Annoy index. Each embedding is identified with a unique index number which facilitates efficient retrieval during the query process.\n",
    "\n",
    "### **Step 3: Building the Index**\n",
    "- Build the Annoy index using a specified number of trees. The number of trees influences the accuracy of the query results; a higher number of trees usually yields more accurate results but at the cost of increased memory usage and build time.\n",
    "\n",
    "### **Step 4: Saving the Index**\n",
    "- Save the built index to a file for future reuse. This step is optional but recommended as it allows the reuse of the index without the need to rebuild it in subsequent runs, saving time and computational resources.\n",
    "\n",
    "### **Step 5: Setting up the Chat Model**\n",
    "- Specify the chat model to be used for generating responses. In this case, the \"claude-3-opus-20240229\" model is chosen for its cost-effectiveness in analyzing large text data.\n",
    "\n",
    "By utilizing Annoy, we streamline the process of setting up a vector database, making it both time-efficient and straightforward, which aligns with our objective of developing an efficient and easy-to-use chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5045d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 15}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "chat_model = \"claude-3-opus-20240229\"\n",
    "\n",
    "# Step 1: Initialize an Annoy index with the correct number of dimensions\n",
    "f = len(contextual_embeddings[0])\n",
    "t = AnnoyIndex(f, 'angular')  \n",
    "\n",
    "# Step 2: Add each embedding to the Annoy index\n",
    "for i, embedding in enumerate(contextual_embeddings):\n",
    "    t.add_item(i, embedding)\n",
    "\n",
    "# Step 3: Build the Annoy index\n",
    "t.build(10) # 10 trees, increase if needed\n",
    "\n",
    "# Step 4: Save the index to a file (optional, but allows for reuse without rebuilding)\n",
    "t.save('contextual_embeddings.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694f393",
   "metadata": {},
   "source": [
    "## Comparison of Different Vector Databases\n",
    "\n",
    "| Feature/Database | Pinecone | Faiss | Annoy | Elasticsearch |\n",
    "|------------------|----------|-------|-------|---------------|\n",
    "| **Ease of Use**  | High (offers a fully-managed service) | Medium (requires understanding of Faiss library specifics) | High (Simple Python library) | Medium (requires setup and configuration) |\n",
    "| **Scalability**  | High (Serverless, scales automatically) | High (Can handle large datasets) | Medium (In-memory, depends on available RAM) | High (Distributed search capabilities) |\n",
    "| **Speed**        | High (optimized for real-time applications) | High (Optimized for speed) | High (Fast query times) | Medium (Depends on the setup) |\n",
    "| **Integration**  | Easy (Python client available) | Medium (Python library) | Easy (Python library) | Easy (REST API and clients in various languages) |\n",
    "| **Cost**         | Paid (with a free tier) | Free (Open-source) | Free (Open-source) | Paid (Cloud versions), Free (self-hosted) |\n",
    "| **Use Cases**    | Real-time applications, Large-scale production environments | Research, Prototypes, Production environments where speed is crucial | Prototypes, Small to Medium scale applications | Enterprise search, Logging, and analytics |\n",
    "\n",
    "### **Recommendations for Use**\n",
    "- **Pinecone**: Ideal for large-scale, real-time applications where ease of use and scalability are paramount.\n",
    "- **Faiss**: Best suited for research and development projects, and production environments where high speed is a priority.\n",
    "- **Annoy**: Recommended for prototypes and smaller scale applications due to its simplicity and in-memory nature.\n",
    "- **Elasticsearch**: A go-to solution for enterprise search solutions, capable of handling logging and analytics alongside vector search capabilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853d0b9",
   "metadata": {},
   "source": [
    "## User Interaction and Response Generation\n",
    "\n",
    "In this final segment of the script, we are crafting a function to manage user inputs and generate informed responses utilizing the RAG setup. Here's a detailed breakdown of the process:\n",
    "\n",
    "### **Step 5: Developing a Function for User Interaction and Response Generation**\n",
    "\n",
    "#### **User's Question Conversion to Embedding**\n",
    "- The user's question is received as an input and transformed into an embedding using the pre-loaded Sentence Transformer model. This step is critical to locate similar contexts in our database to the question posed.\n",
    "\n",
    "#### **Retrieving Similar Embeddings from Annoy Index**\n",
    "- The function then queries the Annoy index to identify embeddings that are most similar to the question's embedding. This is a critical step in obtaining relevant text chunks that would contribute to crafting an informed response.\n",
    "\n",
    "#### **Acquiring Similar Text Segments**\n",
    "- The original text segments that correspond to the most similar embeddings identified are then retrieved. These segments will act as the contextual foundation for generating the response.\n",
    "\n",
    "#### **Creating the Prompt**\n",
    "- A prompt is constructed by amalgamating the user's question with the retrieved text segments, formatted with specific tags to delineate the user's question from the retrieved texts, facilitating a structured and organized input for the Anthropic model.\n",
    "\n",
    "#### **Formulating the System Instruction**\n",
    "- A system instruction is also formulated to guide the Anthropic model to utilize the RAG setup effectively in generating a response. It directs the model to reference the retrieved texts while formulating the answer to the user's question.\n",
    "\n",
    "#### **Message Formation and Response Generation**\n",
    "- A structured message is formulated to interact with the Anthropic model, inclusive of the constructed prompt and a placeholder for the assistant's response.\n",
    "- The Anthropic model is then invoked to generate a response, adhering to specified parameters like the maximum token count and temperature setting, controlling the response's length and variability, respectively.\n",
    "\n",
    "### **Step 6: User Engagement**\n",
    "- The user is prompted to input a question, which is then channeled to the function formulated in step 5.\n",
    "\n",
    "### **Step 7: Presenting the Generated Response**\n",
    "- The response generated by the Anthropic model is then displayed, offering the user a well-informed answer to their question, built upon the relevant contextual data retrieved from the database.\n",
    "\n",
    "This structure establishes a dynamic and interactive chatbot capable of delivering informed responses by optimally utilizing the RAG setup and leveraging the insights obtained from the analyzed PDF document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b98866da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask a question: is tom sawyer a good boy?\n",
      "Based on the passages, it seems Tom Sawyer is a mischievous but ultimately good-hearted boy. A few key points:\n",
      "\n",
      "- Tom frequently gets into trouble at school and with his Aunt Polly, pulling pranks and misbehaving. However, his actions seem driven more by boyish high spirits than real malice.\n",
      "\n",
      "- Tom has a romantic, imaginative nature. He dreams of running away to be a pirate or Indian, and falls head over heels for Becky Thatcher. \n",
      "\n",
      "- Despite his mischief, Tom has a strong moral compass. He feels guilty for hurting Becky's feelings and tries to make it right. He also wants to help the Widow Douglas when he thinks she may be in danger.\n",
      "\n",
      "- Tom is clever and resourceful when he wants to be, like tricking other boys into whitewashing the fence for him. \n",
      "\n",
      "- He has a kind heart under his rough exterior, as shown by his desire to free Jim and be a good friend to Huck Finn.\n",
      "\n",
      "So in summary, Tom is a realistically drawn young boy - flawed and prone to misbehavior, but also imaginative, moral, clever and kind at his core. He means well even if he frequently ends up in trouble. The book portrays him as a lovable scamp more than a bad seed.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create a function to handle user input and generate responses with RAG setup\n",
    "def generate_response_with_rag(question, model, index, client, model_name):\n",
    "    # Transform the user's question into an embedding\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True).cpu().numpy()\n",
    "    \n",
    "    # Query the Annoy index to get the most similar embeddings to the question embedding\n",
    "    similar_items = index.get_nns_by_vector(question_embedding, 5)  # Adjust as needed\n",
    "\n",
    "    # Fetch the original text segments corresponding to the most similar embeddings\n",
    "    similar_texts = [pdf_text_chunks[i] for i in similar_items]\n",
    "\n",
    "    # Create a prompt that includes the user's question and the retrieved texts\n",
    "    prompt = \"<user_question>\" + question + \"</user_question>\" + \"\\n\\n\" + \"\\n\\n\".join([\"<retrieved_text>\" + text + \"</retrieved_text>\" for text in similar_texts])\n",
    "    system_prompt =  \"<instruction>Use the RAG setup to answer the user's question by referring to the retrieved texts.</instruction>\"\n",
    "    \n",
    "    # Create a message for the Anthropic model\n",
    "    message = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "    \n",
    "    # Generate a response using the Anthropic model\n",
    "    response = client.messages.create(\n",
    "        model=chat_model,\n",
    "        max_tokens=2048,  # Adjust as needed\n",
    "        messages=message,\n",
    "        temperature=0.7,  # Adjust as needed\n",
    "        system=system_prompt\n",
    "    )\n",
    "    \n",
    "    return response.content[0].text\n",
    "\n",
    "# Step 6: Get a question from the user and generate a response\n",
    "user_question = input(\"Please ask a question: \")\n",
    "response = generate_response_with_rag(user_question, model, t, client, \"claude-3-opus-20240229\")\n",
    "\n",
    "# Step 7: Print the generated response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "927a9e3b",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 882)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import glob\n",
    "\n",
    "def tokenize_and_embed(output_dir):\n",
    "    # Initialize an empty list to store the content from all files\n",
    "    all_data = []\n",
    "\n",
    "    # Get a list of all the JSON files in the output directory\n",
    "    files = glob.glob(f\"{output_dir}/*.json\")\n",
    "\n",
    "    # Loop through each file and read the content\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            all_data.append(data['analysis_result'])\n",
    "    \n",
    "    # Initialize the TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit the vectorizer to the data\n",
    "    vectorizer.fit(all_data)\n",
    "\n",
    "    # Transform the data into TF-IDF vectors\n",
    "    tfidf_vectors = vectorizer.transform(all_data)\n",
    "\n",
    "    return tfidf_vectors\n",
    "\n",
    "# Get the TF-IDF vectors for the analyzed results\n",
    "tfidf_vectors = tokenize_and_embed(output_dir)\n",
    "\n",
    "# (Optional) Print the shape of the TF-IDF vectors as a verification\n",
    "print(tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737c27f",
   "metadata": {},
   "source": [
    "| Aspect              | Sonnet Model                                                                                        | Opus Model                                                                                                    |\n",
    "|---------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n",
    "| **Cost**               | More economical, making it suitable for processing large volumes of text without escalating costs. | More expensive due to advanced features, justifying its use in generating nuanced responses in the chatbot.   |\n",
    "| **Capabilities**       | Proficient in analyzing and summarizing large text segments, providing a substantial analysis base. | Equipped with advanced features that facilitate more nuanced and sophisticated responses.                      |\n",
    "| **Use in our Script** | Utilized in the text analysis phase to process chunked sections of the PDF and generate summaries.  | Deployed in the user interaction phase to generate high-quality, well-informed responses to user queries.     |\n",
    "| **Quality of Response**| Generates concise summaries without losing the context of the large text segments.                | Enhances user experience by providing detailed and informed responses leveraging the RAG setup.                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf3ea06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IF TIME PERMITS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0001f",
   "metadata": {},
   "source": [
    "## Utilizing Anthropics for Text Analysis\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "In this segment of the script, we are setting up the necessary components to facilitate an in-depth analysis of the text chunks using the Anthropics model. Here, we have chosen the 'claude-3-sonnet-20240229' variant for its cost-effectiveness in analyzing large volumes of text. \n",
    "\n",
    "### **Configuration and Initialization**\n",
    "\n",
    "- **Environment Setup**: We commence by importing the necessary modules and loading the environment variables from a '.env' file. This step ensures that sensitive data like API keys are securely handled.\n",
    "- **Client Initialization**: We proceed to initialize the Anthropics client with the retrieved API key, establishing a connection to leverage the Anthropics platform for analysis.\n",
    "\n",
    "### **Analysis Function**\n",
    "\n",
    "- **Function Definition**: A function named `analyze_with_anthropic` is defined to handle the analysis of text chunks. This function takes in the text chunks as input and returns a list of analysis results.\n",
    "- **Prompt Setup**: A prompt and a system message are set up to guide the Anthropics model in performing the analysis. The prompt instructs the model to analyze the text segments and summarize the key points without losing the context.\n",
    "\n",
    "### **Chunk Analysis**\n",
    "\n",
    "- **Iteration through Chunks**: The function iterates through each text chunk, and for each chunk that doesn't exceed the 100,000 token limit, it constructs a message with the chunk content and the prompt.\n",
    "- **Model Interaction**: The Anthropics model is then invoked to analyze the text chunk, with the results being collected in a list.\n",
    "- **Progress Bar**: A progress bar is displayed to indicate the progress of the analysis process, providing visual feedback on the number of chunks analyzed.\n",
    "\n",
    "### **Output**\n",
    "\n",
    "- **Analysis Results**: After the analysis of all chunks, the function returns a list of analysis results, each corresponding to a text chunk.\n",
    "- **Verification Output**: As a verification step, the first 500 characters of the first analysis result are printed to the console.\n",
    "\n",
    "### **Considerations for RAG Integration**\n",
    "\n",
    "- **Impact on RAG**: It's important to note that opting for larger context windows, resulting in fewer analyzed files, can have implications on the subsequent steps where we integrate the RAG model. Fewer, but more context-rich files might influence the RAG's ability to generate well-rounded responses, as it would have a denser source of reference.\n",
    "- **Balancing Analysis Depth and RAG Effectiveness**: Therefore, a careful balance needs to be struck between the depth of analysis (achieved through larger context windows) and the effectiveness of the RAG model in utilizing these analyzed outputs to generate responses. This balance is key to achieving an optimized and coherent chatbot experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ace5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def chunk_text(text, max_chunk_size=50000):\n",
    "    \"\"\"\n",
    "    Function to chunk the text into smaller pieces with a dynamic chunk size.\n",
    "    The chunk size is determined based on the total word count, the context window limit, \n",
    "    and the consideration to prevent overfitting by not having too large a context window.\n",
    "    \"\"\"\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Calculate the total word count\n",
    "    total_word_count = len(words)\n",
    "    \n",
    "    # Calculate an optimal chunk size based on the total word count and the context window limit\n",
    "    # Additionally, introduce a factor to prevent overfitting by considering the model's token generation limit\n",
    "    chunk_size = min(max_chunk_size, total_word_count // (total_word_count // max_chunk_size), 4096 * 12)\n",
    "    \n",
    "    # Initialize an empty list to store the chunks\n",
    "    chunks = []\n",
    "    \n",
    "    # Iterate through the words and create chunks of the calculated size\n",
    "    for i in tqdm(range(0, total_word_count, chunk_size), desc=\"Chunking text\"):\n",
    "        chunk = ' '.join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Chunk the extracted text into sections based on the calculated optimal chunk size\n",
    "pdf_text_chunks = chunk_text(pdf_text)\n",
    "\n",
    "# Print the first chunk as a verification\n",
    "print(pdf_text_chunks[0][:500])  # Print the first 500 characters of the first chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a59909",
   "metadata": {},
   "source": [
    "## Dynamic Context Window Adjustment\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "In this enhanced approach, we are optimizing the chunk size further to harness the full potential of the model's token generation limit while analyzing the text data. Initially, we establish a chunk size that aligns with the model's token generation capacity, aiming to encapsulate a richer and more detailed context from the outset, considering the total word count in the document, which influences the dynamic adjustment of the chunk size.\n",
    "\n",
    "### **Implementing a Dynamic Context Window**\n",
    "\n",
    "- **Initial Chunk Size**: Set a larger initial chunk size, approximated to the model's token generation limit, to capture a broader and richer context in each chunk.\n",
    "- **Token Utilization**: Estimate the tokens used for the question and retrieved texts, and calculate the available tokens for generating a response.\n",
    "- **Dynamic Chunk Adjustment**: In cases where a chunk exceeds the available tokens for a detailed response, it is further segmented into smaller sections, each analyzed separately. This ensures the utilization of the maximum allowable tokens for generating detailed responses, preventing potential dilution of the analysis due to excessively large context windows.\n",
    "- **Optimized Analysis**: This dynamic adjustment aims not only to prevent potential overfitting issues that might arise from using too large a context window but also to fully utilize the available tokens for generating responses, yielding more detailed and nuanced analysis results.\n",
    "\n",
    "### **Benefits of the Dynamic Approach**\n",
    "\n",
    "- **Richer Insights**: By initially permitting larger context windows, we potentially derive richer insights with more detailed contexts, enhancing the depth and quality of the analysis.\n",
    "- **Preventing Overfitting**: The dynamic adjustment serves to prevent potential overfitting issues that might occur when using an excessively large context window. It adjusts the chunk size to stay within the token generation limit, ensuring a balanced analysis.\n",
    "- **Efficient Utilization of Tokens**: This approach guarantees the most efficient use of the available tokens, aiming to produce more detailed and nuanced analysis results, without losing vital contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68594812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a903c25bee4af0a45d08f28dc85d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing with Anthropics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fc82880aad4899b800cbfabea6c783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28be084dd4a84207b1558fd25a35d176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea9053cc6ca4607b31ea1c7b59b932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9c68969cd949219534c0672f5b9e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaad79976e5436d848304fe4ffaf8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24110bbaedb4451b2ff6679571ba176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1484094766634551a33a92c8fa2dc499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fa42e92e78431984efad35c5fff565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3fc49d35b24c649e5d254c1b27e6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caef7fb7093a4ac1b74a66b6712d4a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f1fae50e3d462aa1bc2e280a6816cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacdb53ff80049419d86c47a419bb4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18146a1d52404e9aa5985b38d1a6ab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e891074b16ab4cfcba7b6c13db43a429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195744bca81d42bc82a3ed9c3cc17523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa548c4a9994fcba1b5be2706653dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7f45fbef8343619dc5a2997c01eb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faef8aee16134fec8341a2141fa1915d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d9f53b59544cfcb3c6aae0df6e4128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a594f8325354696b6df51954d907578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f91249283b748db954d674f4628f87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc509814f0b742f4a58d5eff0f2055d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df840b918feb4dc2b2d24bc1787cf6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4b33806ce345e6a4e0ebd958861490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd1044559c541f4965985faae0cf258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f2c5ab0e774ae7a7729b2adb7c1979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad531b1ff714dfa8046b3f98faa62da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8f0378f14346df86ffeb4bc65d62a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4adb507a2d4435afac5be28123c445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66abaa9f23ea4792bc0c27d28cc2ec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0206ca8e2fac422eb614772652b0fdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4e30fd16534e05ad65f3ff510b6c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0903287280354da6a537015dd276a513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec8c3300c604fac9f69e9670dd055f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c548023b95fb48e380783a265191fedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b01ab2105774a8296c44d7c07aa7122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08642054182748c78d2fad5b486195a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3213cdde6d0c4b338a6f2527241509aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069f617ac63d4fe0b70a5677f6314991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4f62b746db4a918016188501771706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879a0ab8bb4f444e8f996ec30567ac44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9113ad29a6e5432b853547817cb90b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4f92d2406c47b3bcb7cbeeed2a6991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a805985f77340e3900b0234fc20409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0e7683585b41c28da59c583dd79309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e841714012478cbfc3858c6ed62be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee1a21b26df4a938c5ad6afd3b7c244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dcbfa8af47441595d789b77df4f902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af90fb6819d4a3281fc2375131fe7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3827426fc604eb8b5b93a2ac4310df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b542d3733e44e0ae25e1098fa62bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09372d29548f491fb2d13057c468df70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a9140386104b22ab648d13c4d9c75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741f2536829c4a6a99f2b4caf7f9b442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565e852e80af430caa7fe5be757f72fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375183c857a74a0c9b2cc76f682cb1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bfabc8874542358959fb245e03bd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010f12f1ce29464e96c8e5969e404103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ace8393da64d36a0726209aa982d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ac2e6fa11c46d4a492957a62f340f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da152ec0aa3489c9df877bb0feb5c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b1c2ddb3f84e1fa0bf5cac11aab3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9128cf4141394a88afc8dce8f66bbca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c94537ef60643c9b604ac66af0ce110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcd0eec7fd246648a9d9d6bd36bf0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178513d4e993491f89fbc4e372a6e93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf20e5fce924f63b46bfa4631fe164d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec33dc66b0b947c58f7d28e37be65093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab45f959a1d9489c95deaa40acfda692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dc02b70bd44ec392d592e753b96033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8f113abf584599877700ebe2d6d3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec11b63ae40d41ac9f5821fb1d937c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe860034ded4418fbb33275f65802e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d9d80043a14db8926c9c6c390a6bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fc31e046934adeba99397ac7abdd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091d0b76306340f18ef9a5efd7ad727a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf710d5cad2c4ccf9497a1ad908b8cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d20d2f3b3874e21a308c6c0e0307a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2865fb19f1f541189ff5a9756d05cb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14ac677e8124a779eff1d537d1c43f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fe35ae217f4f14b3166f04cf19910a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f8b980b9b842629407e86adaba79d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58386ef743994b209904ebb7e3345555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf4a45ba8874a48bf63120aefdfe4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893421a809094db39bc142c4db1a01b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d667600fcb34d8fb23727ba932465de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dbf9ead75e47a3952f59c6411fc8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e7d9b48b494e64b0d11f85ba6287e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363032371e624d43aa67eb6b7cbb0a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8c79af551844e6aa18bd5f670f6342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3458f645b8c4404b9a534c9991f8a8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ca7f4cc699446498aec0ed67f2ac11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60377b6f398a45c7adceec796ce14c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3774bc9492d94cd18b11c610fc1743ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a53b34ce0b4b709fc0a2c46a62c8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6372c4e63e354cc995b9e168c6dccd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9182a28e384a5689b9cb6c8c630ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58301f7b7e3148f599d1dcce00fe3d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06360cdf0c2547be95b2f600b4b4a160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83f3a9f69744b86a6304e2f1d91604d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d5510c6f80472e96c5f469cdf82d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2464de2819a1468ba1390dabd0cc1257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42b26c13cf849639bde6cd1e7ed0985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e56c97c31334dcca3b784cf439fc55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299d09c375634bfb80ca8891f8fb1d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a708656c1f49e3bcc0c90c02485c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabd11348ae8422380c77b4072ac0b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ea921740aa495f864645b645908c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa73a0dace249d8b5d50c89bea3e7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4977b34dca24552a41f2967c02dfb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c671495d30884d0b95375c462bae5ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d80248f9894b9a88c62cbb03948363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa2f588901241f8919542f364bf8cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e1033da8f241c983aea9bd109159ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013db1aefb3e4b60ab110478f3f55d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcd05ee30224eaf91dfa84095900efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abb97d91ae54d82b35d6c154ef63936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aa1092bfc34a6b92a9a720ae258ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da068c5fe3d846d7bbac138cad11493c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e635afed430e40e8983bfcb56f6ca4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3af15cdc9c4272b2697d3ef8389b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e82bd6e17b4487294e83e0c0d4c6582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e7811190c64f358d1151bb5c37f87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d048280fe5194c0c8f3dcf56fce1378a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920def071349447ba25c5799f099962f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb38ee752b8d4c8fafbeebc444342fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f95b0a9d5fe41d39ad782acf028b559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4828747350c94b95a8dd46775c212ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151082cac68741a48d4294da1d5409a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9723467a05bc4ae9b1386db9d91d19dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8248a0e135784799be599d85fc788f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865835e8125948a4bd2b500c9b5a1fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7cdc06e3824503b702083a5c38d9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7035ef8467a8442d8c169804028115cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3f36a4bb334188a75977ca373d6c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bef2e47f3b24eab9dc42ee9ac3a9210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a8a10a9f794e1999288f5be6f50408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c67e5a07b9406e9513139a09870c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e851aaa76f3a4134bc062a4c4bdb7eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c65af7586b94073958ed57fd930221a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86e9fd5b1a44047bba10768836847fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340cc9a8315c4afdaa5291a834e2e887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c3a86ba0a447358794aaea7ec3e9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ec3c434c9c4cefb39eed63087283e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c7a31926e7488580b40b08fc5f3bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7dbbf33beb46cf9d0ee065f4965ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e2bd7c810e4b36b0b7f187c65a3cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d212af8966984ac5aa0b11faa77db888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aced4f40c05e446383e95716933e22bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37f8d03c806447283055aaaa9b1db6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d849ff86b99e43cba784506f868d1db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec7ec21d9c9498899caeda7453befed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd395f328ea24fa79c74d0b975af89c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f83ae7bf0840f2a093f2b01852b915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809501604ba74cfe86984adf39db9592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2afdb7bd41045329ea79448fbf3e833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ff81721883496c9d14291839f2b5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe1a0213a114a7f8452e5f3547fe895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bfd7961aba4685969d2f75530cb810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d44acd28cd642e88826e546d624238e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dfd6aca9134e058c9ce71233f4aecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd79cb3a28e4727b06739c5a77f18d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3999c770ad46688dad546b63b88990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cae5231e56a454e9cf8a93e341ecc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dfc9dcdbea4a3ab777c28411bb6ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39397aa04b424e3890cd3c8dc1a9fd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3412b1cbe4f1417997fb585945765782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb3c3bbeef54a96ab8533aefa941f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8cd5d1f223497f8f54f288ceacddf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088c6be8582e40c79ae865f2f1cfffa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9bfb715d9d467fbb137784b9af4b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80127c51b1c48dc96f4d13f9b76d371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af2134de11f4e47b4d7f04511b79149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab452ea11db445f295ecc56930fc25f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b580993e618416e904df0555fb6ea91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15772bb6c8094dd3afc783519100e907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0438c17cb04904b451b1905ff80efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ff536793a54b33ad55d7a31f6cabe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0aa593e9eb403a877de587a7c91673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4473003bfd9c436c9f3bca305ee3acf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5208e19e154fd4a861dfe31851d4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11edfbd2fbf4027b626699a6b678347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09087057b2d143f98db775ef667e5369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146445ee390d4d7d99359436a1293ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408855deabff470bb1c8b831125a307f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a4ebe0b409437b91d3cd09c55f125f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b26d57ec0c41cab7f2a3ab2062f11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e430eb470b459b9619e2b27234c697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc455226f4a4fa2b424d751af759c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa2edca8fe644e38873fcf3d7fd8df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6939072946844aee95b0e1ffecde3ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d28fda0c36e4e798ca99bab4d49b539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e8b58e6da6454288b3c9a24cee975a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e758d557a844f882aed277812f0476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f03f17d4fd145a1880bd965ed895558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e39b02706145a19dd6b3127a1b16e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe959c898a2a4fdbbd3eb8f66041aa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf76453f4f3471f821b92084e3b7b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807bb9397c3a4913968c5ae5d469cf4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b87f05edea4ac798b409a887df953e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167f8579890646f2af8cdd0ea7fdc89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4119e140e7471a8f60ee465a40ebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd56e8d5c91542fcb49635da5a24c93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd26a52ac284069a796c2b9fc026bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a2c1d46d6d4a9bae0c8f558a2b6eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e150ec551049279225f66a3ced39d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad4588152542ababe2bca30bb4cf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a6cb2f77994c8fbdb8dd4664d19727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16c81b4c65f483781c33c78eedd60a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6050955db4064a6a949151a1cb2c8b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e490ae71ac794f259b0c392935cd9e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b341a266ad1946ea83fa7cb9bd04496e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8142673af34be58607a454c554c247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9338b2664944a13a651af36380c7585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8f89eb5740405b869ab6aa7b14cd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b754749a33614bff9599aac16be44d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd58c8affe5d4880ac9c50bcff6c3ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a520c07e9240898ef2dec6d9adcacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4748df9be4de4babbbe68bc4a2ebb21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b403a18ec4b641149c7d5619725ca39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d69d1b0b1e437daed4d684b1ad3022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4208e9b6e945d39708f4e218e94b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613ebb1e6fed4f70b1a386f7dec7159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7836a87b7c7a4ecbb21ada87443f47b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771262ad1c964877a9c84d2f877cd798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300680a4bd464646884b3a7375574676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9309ea49a2514a8c8320b539416371d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebec133b723472690fbe0f84720230c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb38f2c83694ee3bb37ba394e7f4d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec343ec75af406a9f5d546f91b50c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21be67074b494f0d90bd51ec19ffeb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dec1a5f73940ae9ded2847fcd1615c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb384ae36f243c4899194b756b3a97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f16e24e58c9449b8d05aa07f0a23f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd21da7ea3d64b33b964681396301e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af1d167b1e473f98556290d4947dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747be66a31c24bf4bfd086ab66c32ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2161cc0911874b9fa2dc875ff3d4f881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd010042439f45d2b92d72b0fdeaf54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b4fa0f88c347e1a5f2f86e7db2a6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1853776ed4a4fdca372006eda87418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4681a49c005b42f09837c2545b3841a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c538c1819564ed0ae30a3978102ce45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e732a0969964ce5969819e480c00f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e473032dec4493da2970351435b37d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42900ac6552c482b979fc33d41f3409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8a8d1abac7434a9a024d80f04bd6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f1d2d5a7c84ea2ba2bef6c2b9eee83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4f231312494f9fa1d8c302025b3993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606036cc540b4181911de583a125e389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f70954dbb5447068f51651cd77f70b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cd09ddd49f4a1f9d10a22295389d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c4993998c451ba3179658ccf699b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da58211bf254f4aa4a418e4a2e99741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d6c2f237dc48dda4edd48011b70e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3e080798044617b53175a443801391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a79fec7d4f4555bb0e7426d4608e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb55ec58f164b92b66e58dc8f2ff75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91c8639096d4ce0bbd44a5fbfdb7958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79af2455fec04b368014fc0f25fdf8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f582515a7d9400d823f05bdb8276417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa5b012b58f47c89c65617f59d98616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac814fe98cd8460ca4d2bcbb1fd869cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1d6365596f464ebfa79db9c09f7c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c61351aff4d411e8988ab43180920ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0893e9d459b34d518115555f5c39c4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786c426b9d744f2ca2dfdd86106cfa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e014d39aef4f72ad4c3d811b609320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf7265faf4b4f6aa666d292c6d50f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca03ba9da01f4b53a9329fce34aaebd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036a257e06804aea9ac492893c43da46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567d8182e2ff408e85ff29ccb5c41fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3965c7460c48efa095856a8f5d3345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200a0504dfaf40499922bab40a1f0044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27766bfb7fac42739c0602f476edf979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8c75f20331443789cbf714bdf41f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2d86dcd7314dc19eea57271e0ea590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e275bab8d649f2b34c61ec176d8542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478fd786ecb04cd0a5c807a3de3590f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1454e534b8043709cc6b7acd0f7c424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b63391099429588ecb6017abed7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44003f64ae1a4b61900a9d577dc3172b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96dcc6229b64e71bc0f2bebd399a39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74046c97d90949eaacd28f35b550f2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3799dcc71949bcb5eab8b2dc4ae6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828311dac0bd47ce872ff689a237c29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb3599b67b546f390c93a5947011d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing a chunk:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise summary of the key points and insights from the given text segment:\n",
      "\n",
      "- This is the preface to Mark Twain's classic novel The Adventures of Tom Sawyer.\n",
      "\n",
      "- Twain states that most of the adventures in the book are based on real events, some from his own childhood experiences and others from his schoolmates' lives.\n",
      "\n",
      "- The characters of Tom Sawyer and Huck Finn are drawn from real people - Tom is a composite character based on three boys Twain knew, while Huck is based on a single i\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "client = Anthropic(\n",
    "    api_key=os.getenv(\"CLAUDE_API_KEY\")\n",
    ")\n",
    "\n",
    "#Set model\n",
    "MODEL_NAME = \"claude-3-sonnet-20240229\"\n",
    "\n",
    "def analyze_with_anthropic(text_chunks):\n",
    "    analysis_results = []\n",
    "    prompt = \"<instruction>Analyze the following text segment and provide a concise summary highlighting the key points and insights without losing context of the content.</instruction>\"\n",
    "    system_message = \"<system>You are a helpful AI assistant aiding in condensing text without losing content context.</system>\"\n",
    "\n",
    "    for chunk in tqdm(text_chunks, desc=\"Analyzing with Anthropics\"):\n",
    "        chunk_word_count = len(chunk.split())\n",
    "        if chunk_word_count <= 100000:  # Ensuring we don't exceed the 100K token limit\n",
    "            # Calculating available tokens for the response considering the tokens used in the prompt and chunk\n",
    "            available_tokens_for_response = 4096 - len((prompt + system_message).split()) \n",
    "            if available_tokens_for_response > 0:\n",
    "                # Splitting the chunk into smaller sections that fit within the available tokens for response\n",
    "                sub_chunk_size = available_tokens_for_response // 3  # Adjust as needed to fit within token limit\n",
    "                sub_chunks = [chunk[i:i+sub_chunk_size] for i in range(0, len(chunk), sub_chunk_size)]\n",
    "\n",
    "                for sub_chunk in sub_chunks:\n",
    "                    message_content = prompt + \"\\n\\n<text_segment>\" + sub_chunk + \"</text_segment>\"\n",
    "                    message = [\n",
    "                        {\"role\": \"user\", \"content\": message_content}, \n",
    "                        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "                    ]\n",
    "                    \n",
    "                    response = client.messages.create(\n",
    "                        model=MODEL_NAME,\n",
    "                        max_tokens=available_tokens_for_response,  # Set to the calculated available tokens to maximize response detail\n",
    "                        messages=message,\n",
    "                        temperature=0.7,\n",
    "                        system=system_message\n",
    "                    )\n",
    "                    analysis_results.append(response.content[0].text)\n",
    "            else:\n",
    "                print(f\"Skipping a chunk as it exceeds the available token limit for a response.\")\n",
    "        else:\n",
    "            print(f\"Skipping a chunk as it exceeds the 100K token limit.\")\n",
    "    return analysis_results\n",
    "\n",
    "# Analyze the text chunks with the Anthropic model\n",
    "anthropic_analysis_results = analyze_with_anthropic(pdf_text_chunks)\n",
    "\n",
    "# Print the first analysis result as a verification\n",
    "print(anthropic_analysis_results[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e5cecb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea131035e8f4c62bc2063ec5d5e7f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving Results to Files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Directory to save the output files\n",
    "output_dir = \"summary-results\"\n",
    "\n",
    "def save_output_to_files(analysis_results, output_dir):\n",
    "    for i, result in enumerate(tqdm(analysis_results, desc=\"Saving Results to Files\")):\n",
    "        # Create a JSON object for each result\n",
    "        result_json = {\n",
    "            \"chunk_number\": i,\n",
    "            \"analysis_result\": result\n",
    "        }\n",
    "        \n",
    "        # Create a file for each result\n",
    "        with open(f\"{output_dir}/result_{i}.json\", \"w\") as f:\n",
    "            json.dump(result_json, f, indent=4)\n",
    "\n",
    "# Save the analysis results to files\n",
    "save_output_to_files(anthropic_analysis_results, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33af71db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f117ef3866b849aa9ec58b20bdafc103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Embeddings:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings created: 287\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Load the BERT-based model\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "\n",
    "def create_contextual_embeddings(output_dir):\n",
    "    embeddings = []\n",
    "    file_paths = glob.glob(f\"{output_dir}/*.json\")\n",
    "\n",
    "    for file_path in tqdm(file_paths, desc=\"Creating Embeddings\"):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            text = data['analysis_result']\n",
    "            embedding = model.encode(text, convert_to_tensor=True)\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Directory where the analyzed text files are saved\n",
    "output_dir = \"summary-results\"\n",
    "\n",
    "# Create contextual embeddings for the analyzed text\n",
    "contextual_embeddings = create_contextual_embeddings(output_dir)\n",
    "\n",
    "# (Optional) Print the number of embeddings created as a verification\n",
    "print(f\"Number of embeddings created: {len(contextual_embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9316546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "chat_model = \"claude-3-opus-20240229\"\n",
    "\n",
    "# Step 1: Initialize an Annoy index with the correct number of dimensions\n",
    "f = len(contextual_embeddings[0])\n",
    "t = AnnoyIndex(f, 'angular')  \n",
    "\n",
    "# Step 2: Add each embedding to the Annoy index\n",
    "for i, embedding in enumerate(contextual_embeddings):\n",
    "    t.add_item(i, embedding)\n",
    "\n",
    "# Step 3: Build the Annoy index\n",
    "t.build(10) # 10 trees, increase if needed\n",
    "\n",
    "# Step 4: Save the index to a file (optional, but allows for reuse without rebuilding)\n",
    "t.save('contextual_embeddings.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb4fb1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask a question: is tom sawyer a good boy?\n",
      "Based on the texts provided, it is difficult to determine definitively whether Tom Sawyer is a \"good boy\" or not. The passages paint a complex picture:\n",
      "\n",
      "On one hand, Tom is described as mischievous and prone to playing hooky from school and getting into scrapes. The text mentions him tricking other boys into whitewashing a fence for him. This suggests he can be manipulative and shirk his responsibilities at times.\n",
      "\n",
      "However, the passages also note that Tom has a \"good heart\" despite his antics. It's mentioned that he testified in court to free a man who had been wrongly accused, even though speaking up was difficult for him. This shows courage and a strong moral compass. \n",
      "\n",
      "Additionally, Tom is a loyal friend to Huck Finn. Their adventures, while reckless at times, demonstrate Tom's imaginative spirit and zest for life. The text implies these qualities endear Tom to others.\n",
      "\n",
      "So in summary, Tom Sawyer seems to be a multi-faceted character who doesn't fit neatly into categories of purely good or bad. He has flaws and gets into plenty of trouble, but also has redeeming and endearing qualities like bravery, integrity and loyalty. Whether one considers him a \"good boy\" likely depends on how much weight is given to his various traits and actions. The limited excerpts provided suggest he is complex mix of mischief and morality.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create a function to handle user input and generate responses with RAG setup\n",
    "def generate_response_with_rag(question, model, index, client, model_name):\n",
    "    # Transform the user's question into an embedding\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True).cpu().numpy()\n",
    "    \n",
    "    # Query the Annoy index to get the most similar embeddings to the question embedding\n",
    "    similar_items = index.get_nns_by_vector(question_embedding, 5)  # Adjust as needed\n",
    "\n",
    "    # Fetch the original text segments corresponding to the most similar embeddings\n",
    "    similar_texts = [pdf_text_chunks[i] for i in similar_items if i < len(pdf_text_chunks)]  # Added a condition to check if 'i' is within the range\n",
    "\n",
    "    # Create a prompt that includes the user's question and the retrieved texts\n",
    "    prompt = \"<user_question>\" + question + \"</user_question>\" + \"\\n\\n\" + \"\\n\\n\".join([\"<retrieved_text>\" + text + \"</retrieved_text>\" for text in similar_texts])\n",
    "    system_prompt =  \"<instruction>Use the RAG setup to answer the user's question by referring to the retrieved texts.</instruction>\"\n",
    "    \n",
    "    # Create a message for the Anthropic model\n",
    "    message = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "    \n",
    "    # Generate a response using the Anthropic model\n",
    "    response = client.messages.create(\n",
    "        model=chat_model,\n",
    "        max_tokens=2048,  # Adjust as needed\n",
    "        messages=message,\n",
    "        temperature=0.7,  # Adjust as needed\n",
    "        system=system_prompt\n",
    "    )\n",
    "    \n",
    "    return response.content[0].text\n",
    "\n",
    "# Step 6: Get a question from the user and generate a response\n",
    "user_question = input(\"Please ask a question: \")\n",
    "response = generate_response_with_rag(user_question, model, t, client, \"claude-3-opus-20240229\")\n",
    "\n",
    "# Step 7: Print the generated response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c84061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
