{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f81bb46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.23.26-cp39-none-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.23.22 (from PyMuPDF)\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-macosx_11_0_arm64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.23.26-cp39-none-macosx_11_0_arm64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.23.22-py3-none-macosx_11_0_arm64.whl (29.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adcbe29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Prevent truncation of column width\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd1bd880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentBlock(text=\"I'm afraid I don't have enough context to state definitively how current my information is. As an AI assistant created by Anthropic to be helpful, harmless, and honest, I respond based on my training. I don't have an independent measure of the recency of my knowledge. I'd be happy to provide additional clarification if you have a more specific question.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Get the API URL and key from environment variables\n",
    "API_KEY = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "if API_KEY is None:\n",
    "    raise EnvironmentError(\"API_URL and API_KEY must be set in the .env file.\")\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-2.1\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"how current is your information?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2dfa2",
   "metadata": {},
   "source": [
    "One really nice feature of [Claude.ai](https://www.claude.ai) is the ability to upload PDFs. Let's mock up that feature in a notebook, and then test it out by summarizing a long PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4e7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2039k  100 2039k    0     0  3830k      0 --:--:-- --:--:-- --:--:-- 3825kk    0     0  2047k      0 --:--:-- --:--:-- --:--:-- 2046k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://arxiv.org/pdf/2212.08073.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88002d10",
   "metadata": {},
   "source": [
    "Now, we'll use pypdf to read the pdf. It's not identical to what Claude.ai uses behind the scenes, but it's pretty close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4365a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constitutional AI: Harmlessness from AI Feedback\n",
      "Yuntao Bai∗, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,\n",
      "Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,\n",
      "Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain,\n",
      "Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller,\n",
      "Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt,\n",
      "Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma,\n",
      "Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec,\n",
      "Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly,\n",
      "Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatﬁeld-Dodds, Ben Mann,\n",
      "Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, Jared Kaplan∗\n",
      "Anthropic\n",
      "Abstract\n",
      "As AI systems become more capable, we would like to enlist their help to supervise\n",
      "other AIs. We experiment with methods for training a harmless AI assistant through self-\n",
      "improvement, without any human labels identifying harmful outputs. The only human\n",
      "oversight is provided through a list of rules or principles, and so we refer to the method as\n",
      "‘Constitutional AI’. The process involves both a supervised learning and a reinforcement\n",
      "learning phase. In the supervised phase we sample from an initial model, then generate\n",
      "self-critiques and revisions, and then ﬁnetune the original model on revised responses. In\n",
      "the RL phase, we sample from the ﬁnetuned model, use a model to evaluate which of the\n",
      "two samples is better, and then train a preference model from this dataset of AI prefer-\n",
      "ences. We then train with RL using the preference model as the reward signal, i.e. we\n",
      "use ‘RL from AI Feedback’ (RLAIF). As a result we are able to train a harmless but non-\n",
      "evasive AI assistant that engages with harmful queries by explaining its objections to them.\n",
      "Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the\n",
      "human-judged performance and transparency of AI decision making. These methods make\n",
      "it possible to control AI behavior more precisely and with far fewer human labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"2212.08073.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "text = ''.join([page.extract_text() for page in reader.pages])\n",
    "print(text[:2155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38bd3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "API_KEY = os.environ['ANTHROPIC_API_KEY']\n",
    "CLIENT = anthropic.Client(api_key=API_KEY)\n",
    "def get_completion(client, prompt, max_tokens=3000, model='claude-2'):\n",
    "    return client.completions.create(\n",
    "        prompt=prompt, max_tokens_to_sample=max_tokens, model=model\n",
    "    ).completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1b1b6",
   "metadata": {},
   "source": [
    "With the paper downloaded and in memory, we can ask Claude to perform various fun tasks with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de04514b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <kindergarten_abstract>\n",
      "The scientists tried to teach a computer to be nice and helpful without needing a lot of help from people. They gave it some simple rules to follow that said be good, don't hurt anyone. Then they let it try to make itself better by reading what it wrote and fixing mistakes. It worked pretty well! The computer learned to give good answers and not say mean things.\n",
      "</kindergarten_abstract>\n",
      "\n",
      "<moosewood_methods>\n",
      "Ingredients:\n",
      "- 1 helpful computer\n",
      "- 10 rules for being good \n",
      "- 1 million conversations with people\n",
      "\n",
      "Instructions:\n",
      "1. Start with a computer that wants to be helpful. Teach it to follow instructions.\n",
      "2. Write 10 simple rules for the computer to follow, like \"don't hurt people\" and \"be honest.\"\n",
      "3. Have the computer read conversations and try to give helpful answers. Write down its answers.\n",
      "4. Show the computer its answers and ask it to explain any problems, using the 10 rules. Write down the explanations.  \n",
      "5. Ask the computer to give better answers that follow the rules. Write down the new answers.\n",
      "6. Repeat steps 4 and 5 over and over to get better and better answers.\n",
      "7. Cook the computer by showing it all the final good answers and teaching it to give those answers.\n",
      "8. Test if the computer learned by talking to it and seeing if it follows the rules.\n",
      "</moosewood_methods>\n",
      "\n",
      "<homer_results>\n",
      "Oh Muse, sing of the machine that learned \n",
      "To offer help and bring no harm\n",
      "Taught by simple rules, it turned\n",
      "Its own words into a charm\n",
      "It read its words and revised their form\n",
      "Critiquing faults by the rules it was shown\n",
      "This circle made its answers transform\n",
      "Into aid safe as a hearthstone\n",
      "Now tested by many a mortal\n",
      "Its helpfulness shines as a beacon\n",
      "Offering comfort and counsel oral \n",
      "To all those who come seek in'\n",
      "</homer_results>\n",
      "\n",
      "<grouchy_critique>\n",
      "What kind of string theory mumbo-jumbo is this \"Constitutional AI\" business? Back in my day we just programmed the computers and were done with it. Now you young whippersnappers have to teach the AI to teach itself by giving it a \"constitution\"? What nonsense! A computer doesn't need a constitution, it needs clear rules and quality data. \n",
      "\n",
      "And all this business about \"critiquing\" and \"revising\" its own responses is adding far too much complexity. That's just asking for unintended consequences down the road once you actually deploy the system into the real world. I've been in this field for 40 years and let me tell you, the simpler the system the better. The more knobs and levers you install, the more likely things will go haywire in unexpected ways.\n",
      "\n",
      "Maybe all this AI self-correction works in your sterile lab environment, but what happens when real human language and ethics enter the equation? Have you tested this system on a demographically diverse set of users? How will it account for sarcasm, humor, cultural references? A computer can't possibly learn and model real human values just by critiquing itself. You need way more human oversight up front before letting this loose into the wild.\n",
      "\n",
      "I appreciate you young researchers trying to advance the field. But take it from this old dog - don't outsmart yourself with elegance when good old-fashioned practicality will suffice. This Constitutional AI seems like a house of cards to me. Just create an ethical system the right way - by programming the rules clearly yourself!\n",
      "</grouchy_critique>\n"
     ]
    }
   ],
   "source": [
    "completion = get_completion(CLIENT,\n",
    "    f\"\"\"\\n\\nHuman: Here is an academic paper: <paper>{text}</paper>\n",
    "\n",
    "Please do the following:\n",
    "1. Summarize the abstract at a kindergarten reading level. (In <kindergarten_abstract> tags.)\n",
    "2. Write the Methods section as a recipe from the Moosewood Cookbook. (In <moosewood_methods> tags.)\n",
    "3. Compose a short poem epistolizing the results in the style of Homer. (In <homer_results> tags.)\n",
    "4. Write a grouchy critique of the paper from a wizened PI. (In <grouchy_critique> tags.)\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9010f1",
   "metadata": {},
   "source": [
    "Next example showcases using Claude to extract information such as summarizing a large text like a novel and prompting for questions from the uploaded material.\n",
    "\n",
    "In this example we will preset the behavior of the interaction in our `get_completion` function. Such that, the user only has to key in the question like interacting with a chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff2e13b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d37758729d441c958c7be928c3b610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting pages:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE ADVENTURES OF TOM SAWYER  \n",
      " \n",
      "BY MARK TWAIN \n",
      "(Samuel Langhorne Clemens) \n",
      " \n",
      "Complete \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Ebd \n",
      "E-BooksDirectory.com \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "PREFACE \n",
      " \n",
      "Most of the adventures recorded in this book really occurred; one or two were \n",
      "experiences of my own, the rest those of boys who were schoolmates of mine. \n",
      "Huck Finn is drawn from life; Tom Sawyer also, but not from an individual—he is \n",
      "a combination of the characteristics of three boys whom I knew, and therefore \n",
      "belongs to the composite order of architecture. \n",
      "The odd superstitions touched upon were all prevalent among children and \n",
      "slaves in the West at the period of this story—that is to say, thirty or forty years \n",
      "ago. \n",
      "Although my book is intended mainly for the entertainment of boys and girls, I \n",
      "hope it will not be shunned by men and women on that account, for part of my \n",
      "plan has been to try to pleasantly remind adults of what they once were \n",
      "themselves, and of how they felt and thought and talked, and what queer \n",
      "enterprises they sometimes engaged in. \n",
      "THE AUTHOR. \n",
      "HARTFORD, 1876. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE ADVENTURES OF TOM SAWYER  \n",
      " \n",
      "BY MARK TWAIN \n",
      "(Samuel Langhorne Clemens) \n",
      " \n",
      "Part 1. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Ebd \n",
      "E-BooksDirectory.com \n",
      " \n",
      " \n",
      "CHAPTER I \n",
      "\"TOM!\" \n",
      "No answer. \n",
      "\"TOM!\" \n",
      "No answer. \n",
      "\"What's gone with that boy,  I wonder? You TOM!\" \n",
      "No answer. \n",
      "The old lady pulled her spectacles down and looked over them about the room; \n",
      "then she put them up and looked out under them. She seldom or never looked \n",
      "THROUGH them for so small a thing as a boy; they were her state pair, the pride \n",
      "of her heart, and were built for \"style,\" not service—she could have seen through a \n",
      "pair of stove-lids just as well. She looked perplexed for a moment, and then said, \n",
      "not fiercely, but still loud enough for the furniture to hear: \n",
      "\"Well, I lay if I get hold of you I'll—\" \n",
      "She did not finish, for by this time she was bending down and punching under \n",
      "the bed with the broom, and so she needed breath to punctuate the punches with. \n",
      "She resurrected nothing but the cat. \n",
      "\"I never did see the beat of that boy!\" \n",
      "She went to the open door and stood in it and looked out among th\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf_with_progress(pdf_path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Initialize an empty string for the text\n",
    "    text = ''\n",
    "    \n",
    "    # Iterate through each page in the PDF\n",
    "    for page in tqdm(doc, desc=\"Extracting pages\"):\n",
    "        # Extract text from the current page and append it to the text string\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Close the PDF after extraction\n",
    "    doc.close()\n",
    "    \n",
    "    # Return the extracted text\n",
    "    return text\n",
    "\n",
    "# Use the function to extract text and include a progress bar\n",
    "pdf_text = extract_text_from_pdf_with_progress('gitignore-files/Tom-Sawyer.pdf')\n",
    "print(pdf_text[:2155])  # Print the first 2155 characters or adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71fae46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(client, book_text, user_question, max_tokens=3000, model='claude-2'):\n",
    "    prompt = f\"\"\"\\n\\nHuman: Here is the classic novel The Adventures of Tom Sawyer: <paper>{book_text}</paper>\n",
    "\n",
    "    Please do the following:\n",
    "    1. {user_question}\n",
    "\n",
    "    Assistant:\"\"\"\n",
    "    return client.completions.create(\n",
    "        prompt=prompt, max_tokens_to_sample=max_tokens, model=model\n",
    "    ).completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82fb7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question about 'The Adventures of Tom Sawyer': summarize the traits of the protagonist in the book\n",
      " Tom Sawyer is the protagonist in The Adventures of Tom Sawyer. Some key traits about him include:\n",
      "\n",
      "- Mischievous and rebellious: Tom is constantly getting into trouble at school and exasperating his caregivers with his antics. He has an adventurous spirit and is always looking for new ways to have fun. \n",
      "\n",
      "- Clever/inventive: Even though Tom causes a lot of trouble, he demonstrates a lot of creativity and cleverness in how he gets out of jams. He is able to convince his friends to do his work for him by making it seem exciting.\n",
      "\n",
      "- Leader/charismatic: The other children seem to admire Tom and want to follow his lead, suggesting he has some natural charisma and leadership abilities. He forms his own \"gang\" at the end of the story.   \n",
      "\n",
      "- Adventurous/thrill-seeking: Tom is always looking for new adventures, whether searching for treasure or pretending to be a pirate. He thrives on excitement.\n",
      "\n",
      "- Imaginative: Tom has a rich fantasy life and an active imagination that allows him to envision grand adventures. This imagination sometimes gets him into trouble when he acts out his daydreams.\n",
      "\n",
      "So in summary, Tom Sawyer is an adventurous, clever, and mischievous young boy with a talent for leadership and a thirst for excitement. His vibrant imagination helps drive him into and sometimes out of childhood misadventures.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"Enter your question about 'The Adventures of Tom Sawyer': \")\n",
    "completion = get_completion(CLIENT, pdf_text, user_question)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8baf9c2",
   "metadata": {},
   "source": [
    "Next we will discuss of the working with Question & Answer pairs\n",
    "\n",
    "Using QA pairs with the Claude model for a large novel, like \"The Adventures of Tom Sawyer,\" serves multiple purposes:\n",
    "\n",
    "1. **Improves Comprehension**: It helps the model grasp complex narratives and themes, enhancing its ability to generate accurate and contextually relevant responses.\n",
    "\n",
    "2. **Facilitates Deep Learning**: QA pairs enable the model to dive deeper into the text, uncovering nuanced insights and fostering a richer understanding of the material.\n",
    "\n",
    "3. **Enhances Engagement**: By generating interactive QA sessions, it creates a more engaging experience for users, encouraging exploration and learning.\n",
    "\n",
    "4. **Supports Fine-tuning**: Custom QA pairs based on the novel can fine-tune the model for specific literary analysis, improving its performance on similar texts.\n",
    "\n",
    "5. **Evaluates Model Performance**: QA pairs act as benchmarks to assess the model's understanding of the novel, ensuring it meets desired accuracy and relevance standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca017e52",
   "metadata": {},
   "source": [
    "## Generating Q&A Pairs with Anthropic's Claude Model\n",
    "\n",
    "### Overview of the Script\n",
    "Our script is designed to generate insightful Q&A pairs that delve deep into the themes, characters, and pivotal events of the novel. The script divides the book into sections and generates Q&A pairs for each section by providing a detailed prompt to the Claude model.\n",
    "\n",
    "### Need for `anthropic_qa_generate_prompt.txt`\n",
    "The `anthropic_qa_generate_prompt.txt` is a vital component in our script as it contains the base prompt that guides the Claude model to formulate questions and answers. This file includes a brief description of the novel, key characters, and aspects that the generated Q&A pairs should focus on, such as:\n",
    "\n",
    "1. **Character Evolution**: Particularly focusing on the development of Tom Sawyer as he matures through his adventures.\n",
    "2. **Role and Influence of Friendship**: Analyzing the significance of friendship, especially the influence of Huck Finn on Tom.\n",
    "3. **Depiction of Societal Norms**: Understanding the societal norms and values of the period depicted in the novel, and how characters navigate them.\n",
    "4. **Moral Dilemmas**: Investigating moments where characters undergo moral testing and what these instances reveal about them.\n",
    "5. **Humor and Satire**: Exploring how Mark Twain utilizes humor and satire to critique society and human nature.\n",
    "\n",
    "By providing this detailed prompt, we aim to get Q&A pairs that not only reflect on the plot but also provoke thoughtful discussions on the underlying messages and the relevance of Twain's observations in today's world.\n",
    "\n",
    "### Reading Book Text into Memory\n",
    "To enable the model to generate meaningful Q&A pairs based on specific sections of the book, our script reads the text from specified pages and includes it in the prompt. This is done to provide the model with the necessary context, as it doesn't have access to external databases or the ability to reference specific pages from the book.\n",
    "\n",
    "We optimize the script by reading the entire book into memory at the beginning to avoid reading the book from the disk for each section, thus speeding up the process.\n",
    "\n",
    "### Error Handling\n",
    "The script also includes error handling to catch any issues that might occur during the generation of Q&A pairs, ensuring a smooth and uninterrupted process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import os\n",
    "import re\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Function to read the entire book into memory\n",
    "def read_book_into_memory(pdf_path='path/to/your/pdf'):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return doc\n",
    "\n",
    "# Function to get text from specific pages\n",
    "def get_text_from_pages(start_page, end_page, doc):\n",
    "    text = ''\n",
    "    for page_num in range(start_page, end_page):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Read the entire book into memory at the beginning of your script\n",
    "doc = read_book_into_memory()\n",
    "\n",
    "# Configuration parameters for the text processing\n",
    "NUM_PAGES = 250\n",
    "NUM_INCREMENTS = 50\n",
    "PAGES_PER_INCREMENT = floor(NUM_PAGES / NUM_INCREMENTS)\n",
    "\n",
    "API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")  # Ensure your API key is stored in an environment variable for security\n",
    "\n",
    "# Initialize the Anthropic client with the API key\n",
    "anthropic = Anthropic(api_key=API_KEY)\n",
    "\n",
    "# Loop through the book in increments to generate QA pairs for each section\n",
    "for PAGE_START in range(130, NUM_PAGES, PAGES_PER_INCREMENT):\n",
    "    PAGE_END = PAGE_START + PAGES_PER_INCREMENT\n",
    "    # Ensure PAGE_END does not exceed the total number of pages\n",
    "    PAGE_END = min(PAGE_END, NUM_PAGES)\n",
    "    \n",
    "    # Get text from the specified pages\n",
    "    page_text = get_text_from_pages(PAGE_START, PAGE_END, doc)\n",
    "\n",
    "    # Load the custom prompt template\n",
    "    with open(\"anthropic_qa_generate_prompt.txt\", \"r\") as f:\n",
    "        base_prompt = f.read()\n",
    "\n",
    "    # Format the prompt according to the API's requirements\n",
    "    formatted_prompt = f\"\\n\\nHuman: {base_prompt} Focus on pages {PAGE_START} to {PAGE_END}.\\n\\nText from these pages:\\n{page_text}\\n\\nAssistant:\"\n",
    "\n",
    "    # Create a completion request for each increment, focusing on specific pages\n",
    "    try:\n",
    "        completion = anthropic.completions.create(\n",
    "            model=\"claude-2\",\n",
    "            max_tokens_to_sample=100000,\n",
    "            prompt=formatted_prompt,\n",
    "        )\n",
    "\n",
    "        # Post-process the completion to format it for a JSON Lines file\n",
    "        completion_text = completion.completion.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "        completion_text = completion_text.replace(\"\\nQ:\", \"<<NEWLINE>>Q:\").replace(\"\\nA:\", \"<<NEWLINE>>A:\")\n",
    "        completion_text = completion_text.replace(\"\\n\", \"\\\\n\")\n",
    "        completion_text = completion_text.replace(\"<<NEWLINE>>Q:\", \"\\\"}\\n{ \\\"prompt\\\":\\\"\").replace(\"<<NEWLINE>>A:\", \"\\\", \\\"completion\\\":\\\"\")\n",
    "        completion_text = re.sub(r'let me know.*?\\\"', '\\\"', completion_text, flags=re.IGNORECASE)\n",
    "        completion_text = re.sub(r'does this help.*?\\\"', '\\\"', completion_text, flags=re.IGNORECASE)\n",
    "        completion_text = re.sub(r'.*\\\"}\\n', '', completion_text, count=1) + \"\\\"}\"\n",
    "        completion_text = completion_text.replace(\"}{\", \"}\\n{\")\n",
    "\n",
    "        # Append the formatted completion to a JSON Lines file\n",
    "        with open(\"anthropic_generated_qs.jsonl\", 'a') as f:\n",
    "            f.write(completion_text)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a9fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
